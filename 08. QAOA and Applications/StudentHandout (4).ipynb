{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Quantum Approximate Optimization Algorithm (QAOA) — Detailed Notes (Session 8)\n",
        "**Course:** CS490/5590 — Quantum Computing Applications in Data Science, AI, & Deep Learning  \n",
        "**Instructor:** Luke Miller  \n",
        "\n",
        "> **Purpose.**  These notes expand the Session-8 slides, giving a stand-alone explanation of QAOA, its implementation in Qiskit, and its relevance to combinatorial-optimization tasks in data science. Mini-exercises with concise solutions appear at the end.\n",
        "\n",
        "---\n",
        "\n",
        "## Session Road-map  \n",
        "\n",
        "1. Recap: Phase estimation vs. variational depth  \n",
        "2. Combinatorial optimisation landscape  \n",
        "3. QAOA foundations — cost & mixer Hamiltonians  \n",
        "4. Worked example: MaxCut on a 3-vertex graph  \n",
        "5. Variational parameter optimisation loop  \n",
        "6. QAOA in Qiskit (QuadraticProgram → circuit)  \n",
        "7. Performance, noise, barren plateaus  \n",
        "8. AI / DS use-cases  \n",
        "9. Q&A  \n",
        "\n",
        "---\n",
        "\n",
        "## 0) Why QAOA after Shor/QPE?\n",
        "\n",
        "| Method | Strength | Weakness |\n",
        "|--------|----------|----------|\n",
        "| **QPE/Shor** | Provable speedups | Requires deep, error-corrected circuits |\n",
        "| **QAOA** | Shallow variational ansatz, NISQ-friendly | No proven exponential speedup; classical optimiser overhead |\n",
        "\n",
        "---\n",
        "\n",
        "## 1) Combinatorial optimisation primer  \n",
        "\n",
        "| Problem | Objective (Ising form) | Typical ML link |\n",
        "|---------|-----------------------|-----------------|\n",
        "| MaxCut | maximise $\\sum_{(i,j)\\in E}\\tfrac{1}{2}(1-Z_iZ_j)$ | Graph clustering / community detection |\n",
        "| TSP | minimise path length (sum) | Routing, sequence alignment |\n",
        "| Knapsack | maximise $\\sum v_i x_i$ s.t. $\\sum w_i x_i \\le W$ | Feature subset selection |\n",
        "\n",
        "Classically NP-hard → heuristics or relaxations. Quantum: hope QAOA + quantum sampling gives better approximation for certain instances.\n",
        "\n",
        "---\n",
        "\n",
        "## 2) QAOA overview  \n",
        "\n",
        "- **Input**: problem encoded as cost Hamiltonian $H_C$ (diagonal in computational basis).  \n",
        "- **Ansatz** of depth $p$:\n",
        "\n",
        "$$\n",
        "|\\psi_{p}(\\boldsymbol{\\gamma},\\boldsymbol{\\beta})\\rangle\n",
        "  := \\left[\\prod_{k=1}^{p}e^{-i\\beta_k H_B}e^{-i\\gamma_k H_C}\\right]\\,|+\\rangle^{\\otimes n},\n",
        "$$\n",
        "  where $H_B=\\sum_i X_i$.\n",
        "\n",
        "- **Objective**: maximise $F(\\boldsymbol{\\gamma},\\boldsymbol{\\beta})=\\langle\\psi_p|H_C|\\psi_p\\rangle$.\n",
        "\n",
        "- **Hybrid loop**: evaluate $F$ via sampling; classical optimiser updates parameters.\n",
        "\n",
        "- **Depth** $p$ ↔ quality; $p=1$ often competitive with simple heuristics.\n",
        "\n",
        "---\n",
        "\n",
        "## 3) MaxCut: canonical benchmark  \n",
        "\n",
        "### 3.1 Encoding  \n",
        "\n",
        "For unweighted graph $G=(V,E)$:\n",
        "\n",
        "$$\n",
        "H_C = \\frac12\\sum_{(i,j)\\in E}(I-Z_iZ_j).\n",
        "$$\n",
        "\n",
        "Cut value = expectation of $H_C$.\n",
        "\n",
        "### 3.2 Cost-unitary  \n",
        "\n",
        "Each edge $(i,j)$:\n",
        "\n",
        "$$\n",
        "e^{-i\\gamma (I-Z_iZ_j)/2} =\n",
        "  \\bigl(\\mathrm{CZ}_{ij}\\bigr)\\,R_Z^{(i)}(\\gamma)\\,R_Z^{(j)}(\\gamma)\\,\\mathrm{CZ}_{ij},\n",
        "$$\n",
        "where $\\mathrm{CZ}$ is controlled-Z, $R_Z(\\gamma)=e^{-i\\gamma Z/2}$.\n",
        "\n",
        "### 3.3 Mixer-unitary  \n",
        "\n",
        "Single-qubit $R_X(2\\beta)$ on all qubits.\n",
        "\n",
        "---\n",
        "\n",
        "## 4) Worked example: triangle graph (3 vertices) with $p=1$\n",
        "\n",
        "```python\n",
        "from qiskit import QuantumCircuit\n",
        "from math import pi\n",
        "\n",
        "gamma, beta = 0.7, 0.34\n",
        "qc = QuantumCircuit(3)\n",
        "\n",
        "# 1. |+> state\n",
        "qc.h(range(3))\n",
        "\n",
        "# 2a. Cost unitary (edges 01, 12, 02)\n",
        "edges = [(0,1), (1,2), (0,2)]\n",
        "for i,j in edges:\n",
        "    qc.cx(i,j)\n",
        "    qc.rz(-2*gamma, j)\n",
        "    qc.cx(i,j)\n",
        "\n",
        "# 2b. Mixer unitary\n",
        "qc.rx(2*beta, range(3))\n",
        "\n",
        "qc.measure_all()\n",
        "print(qc.draw('text'))\n",
        "```\n",
        "With $(\\gamma,\\beta)$ near optimum, sampling shows cut value ≈ 1.5 (classical optimum 2).\n",
        "\n",
        "---\n",
        "\n",
        "## 5) Parameter-optimisation strategies  \n",
        "\n",
        "| Optimiser | Pros | Cons |\n",
        "|-----------|------|------|\n",
        "| COBYLA | Derivative-free, robust | Many iterations |\n",
        "| SPSA | Low shots per step | Sensitive to hyper-params |\n",
        "| Bayesian (Qiskit Aqua) | Sample-efficient | Overhead grows with dim |\n",
        "\n",
        "**Warm-starting**: use analytic solutions for small graphs or interpolation as $n$ grows; mitigates barren plateaus.\n",
        "\n",
        "---\n",
        "\n",
        "## 6) QAOA in Qiskit  \n",
        "\n",
        "```python\n",
        "from qiskit_optimization.applications import Maxcut\n",
        "from qiskit_optimization.algorithms import MinimumEigenOptimizer\n",
        "from qiskit.algorithms import QAOA\n",
        "from qiskit.algorithms.optimizers import COBYLA\n",
        "from qiskit.primitives import Sampler\n",
        "\n",
        "# define weighted graph\n",
        "w = [[0,1,1],[1,0,1],[1,1,0]]\n",
        "problem = Maxcut(w).to_quadratic_program()\n",
        "\n",
        "qaoa = QAOA(Sampler(), optimizer=COBYLA(maxiter=50), reps=1)\n",
        "solver = MinimumEigenOptimizer(qaoa)\n",
        "result = solver.solve(problem)\n",
        "print(\"MaxCut value:\", Maxcut.max_cut_value(result.x, w))\n",
        "```\n",
        "\n",
        "For NISQ back-end: wrap `Sampler(backend=provider.get_backend('ibmq_quito'), resilience_level=1)` and rely on built-in read-out mitigation.\n",
        "\n",
        "---\n",
        "\n",
        "## 7) Performance considerations  \n",
        "\n",
        "- **Approximation ratio** improves with $p$; analytic bound $p=1$ ≥ 0.5 for rings; empirically 0.7–0.9 on random graphs.  \n",
        "- **Noise**: depth ∝ $p|E|$. On 15-edge graph, $p=3$ uses ~100 two-qubit gates → feasible with error-mitigation.  \n",
        "- **Barren plateaus**: gradient variance $\\sim e^{-n}$ for generic ansatz; structured QAOA appears less susceptible at small $p$.\n",
        "\n",
        "---\n",
        "\n",
        "## 8) AI / DS use-cases  \n",
        "\n",
        "| Task | QAOA role |\n",
        "|------|-----------|\n",
        "| **Graph clustering** | MaxCut / community detection as cost Hamiltonian. |\n",
        "| **Feature selection** | Binary string selects features; cost = validation loss + penalty. |\n",
        "| **Portfolio optimisation** | QUBO encoding risk-return trade-off. |\n",
        "| **Neural architecture search** | Discrete hyper-parameters mapped to Ising variables. |\n",
        "\n",
        "**Hybrid flow**: classical pre-screening → QAOA on reduced instance → classical post-processing.\n",
        "\n",
        "---\n",
        "\n",
        "## 9) Mini-exercises (answers in Appendix)\n",
        "\n",
        "1. Show that for a single edge, $e^{-i\\gamma Z_iZ_j/2}$ equals a CX-sandwiched $R_Z$ rotation as used above.  \n",
        "2. Derive analytic optimum $(\\gamma^*,\\beta^*)$ for MaxCut on a 2-vertex graph.  \n",
        "3. Implement QAOA $p=2$ on a square (4 vertices, ring) in Qiskit; report approximation ratio.  \n",
        "4. Explain why increasing $p$ mitigates barren plateaus on small graphs but may re-introduce them on large $n$.  \n",
        "5. Using depolarising error $p=0.01$ per CNOT, estimate success-probability loss for $p=3$ QAOA on triangle (9 CNOTs).\n",
        "\n",
        "---\n",
        "\n",
        "## 10) FAQ  \n",
        "\n",
        "- **“Why choose $H_B=\\sum X_i$?** For unconstrained problems binary-domain $±1$, this mixer keeps uniform exploration. Constrained problems need custom mixers (e.g., XY-mixer for fixed-weight).  \n",
        "- **“Does QAOA guarantee better than classical?”** Not proved; for some graphs $p=1$ equals classical random cut, but $p\\to\\infty$ approaches optimum.  \n",
        "- **“How to initialise parameters?”** Grid search for $p=1$; Fourier heuristic or interpolation for larger $p$.  \n",
        "- **“What about gradient-based optimisation?”** Parameter-shift rule works but may suffer from shot noise.  \n",
        "\n",
        "---\n",
        "\n",
        "## 11) Summary (Session 8)\n",
        "\n",
        "- QAOA alternates cost-driven and mixer evolutions; depth $2p$ layers.  \n",
        "- MaxCut serves as canonical benchmark; cost unitary uses ZZ rotations; mixer uses RX rotations.  \n",
        "- Hybrid loop tunes $\\gamma,\\beta$ to maximise expected cost; classical optimiser is key.  \n",
        "- Shallow circuits make QAOA compatible with NISQ, but noise and barren plateaus remain hurdles.  \n",
        "- Practical applications span graph partitioning, feature selection, portfolio optimisation.\n",
        "\n",
        "---\n",
        "\n",
        "## 12) Looking ahead  \n",
        "\n",
        "- **Next Session:** Variational Quantum Eigensolver (VQE) for chemistry and kernel-based QML.  \n",
        "- **Homework 3:** formulate feature-selection QUBO, implement $p=2$ QAOA, compare to greedy feature ranking.\n",
        "\n",
        "---\n",
        "\n",
        "## Appendix — mini-exercise solutions (sketch)\n",
        "\n",
        "1. Conjugation identity: $CX\\,(I\\otimes R_Z(\\phi))\\,CX = e^{-i\\phi Z_iZ_j/2}$.  \n",
        "2. Two-vertex graph: optimum $\\gamma^*=\\pi/8,\\; \\beta^*=\\pi/4$ achieves ratio 1.  \n",
        "3. Simulation shows ratio ≥ 0.92 for ring-4 at $p=2$ with tuned params.  \n",
        "4. Parameter count $2p$ grows; landscape flattens for random initialisation on large $n$.  \n",
        "5. Success drop ≈ $1-(1-p)^{9}\\approx 8.6\\,\\%$.\n",
        "\n"
      ],
      "metadata": {
        "id": "jGckbqdARP07"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DzRpdOT7SeNI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}